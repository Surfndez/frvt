#include <algorithm>

#include "SphereFaceRecognizer.h"

#include <inference_engine.hpp>
#include <opencv2/imgproc.hpp>

#include <opencv2/highgui.hpp>

using namespace FRVT_11;
using namespace InferenceEngine;

cv::Mat
CropImage(const cv::Mat& image, const std::vector<int>& landmarks)
{
    std::vector<int> xPoints;
    std::vector<int> yPoints;
    for (int i = 0; i < 10; i += 2) {
        xPoints.push_back(landmarks[i]);
        yPoints.push_back(landmarks[i+1]);
    }

    int xMin = *std::min_element(xPoints.begin(), xPoints.end());
    int xMax = *std::max_element(xPoints.begin(), xPoints.end());
    int yMin = *std::min_element(yPoints.begin(), yPoints.end());
    int yMax = *std::max_element(yPoints.begin(), yPoints.end());
    
    int w = (xMax - xMin);
    int h = (yMax - yMin);
    
    int x1 = xMin - int(w * 0.75);
    int x2 = xMax + int(w * 0.75);
    int y1 = yMin - int(h * 0.75);
    int y2 = yMax + int(h * 0.75);

    x1 = std::max(0, x1);
    x2 = std::min(image.cols, x2);
    y1 = std::max(0, y1);
    y2 = std::min(image.rows, y2);

    cv::Mat cropped = image(cv::Range(y1, y2), cv::Range(x1, x2));

    //cv::imwrite("/home/administrator/nist/frvt/debug/fa_cropped.png", cropped);

    return cropped;
}

cv::Mat
NormalizeImage(const cv::Mat& image, const std::vector<int>& landmarks)
{
    // crop
    cv::Mat cropped = CropImage(image, landmarks);

    // To gray scale
    cv::Mat gray;
    cv::cvtColor(cropped, gray, cv::COLOR_BGR2GRAY);

    // normalized
    gray.convertTo(gray, CV_32FC1);
    gray /= 255;
    gray -= 0.5;

    // resize
    cv::resize(gray, gray, cv::Size(128, 128), 0, 0, cv::INTER_LINEAR);

    return gray;
}

SphereFaceRecognizer::SphereFaceRecognizer(const std::string &configDir)
{
    std::string sphereModelPath = configDir + "/sphereface_v3-sphereface_v3_28_dm120_cosineface_bbox_0-4075000_features";

    // --------------------------- 1. Load Plugin for inference engine -------------------------------------
    mInferencePlugin = std::make_shared<InferencePlugin>(PluginDispatcher().getSuitablePlugin(TargetDevice::eCPU));

    // --------------------------- 2. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
    CNNNetReader network_reader;
    network_reader.ReadNetwork(sphereModelPath + ".xml");
    network_reader.ReadWeights(sphereModelPath + ".bin");
    network_reader.getNetwork().setBatchSize(1);
    mCNNNetwork = std::make_shared<CNNNetwork>(network_reader.getNetwork());
    // -----------------------------------------------------------------------------------------------------

    // --------------------------- 3. Configure input & output ---------------------------------------------
    // --------------------------- Prepare input blobs -----------------------------------------------------
    InputInfo::Ptr input_info = mCNNNetwork->getInputsInfo().begin()->second;
    std::string input_name = mCNNNetwork->getInputsInfo().begin()->first;

    input_info->setLayout(Layout::NCHW);
    input_info->setPrecision(Precision::FP32);

    // --------------------------- Prepare output blobs ----------------------------------------------------
    DataPtr output_info = mCNNNetwork->getOutputsInfo().begin()->second;
    std::string output_name = mCNNNetwork->getOutputsInfo().begin()->first;

    output_info->setPrecision(Precision::FP32);
    // -----------------------------------------------------------------------------------------------------

    // Set private members
    mInputName = input_name;
    mOutputName = output_name;
}

SphereFaceRecognizer::~SphereFaceRecognizer() {}

std::vector<float>
SphereFaceRecognizer::Infer(const ImageData& imageData, const std::vector<int>& landmarks) const
{
    std::cout << "Sphere inference... " << std::endl;

    cv::Mat image(imageData.height, imageData.width, CV_8UC3, imageData.data.get());
    
    image = NormalizeImage(image, landmarks);

    // --------------------------- 4. Loading model to the plugin ------------------------------------------
    auto mExecutableNetwork = std::make_shared<ExecutableNetwork>(mInferencePlugin->LoadNetwork(*mCNNNetwork, {}));
    // -----------------------------------------------------------------------------------------------------

    // --------------------------- 5. Create infer request -------------------------------------------------
    InferRequest infer_request = mExecutableNetwork->CreateInferRequest();
    // -----------------------------------------------------------------------------------------------------
        
    // --------------------------- 6. Prepare input --------------------------------------------------------
    Blob::Ptr input = infer_request.GetBlob(mInputName);
    auto input_data = input->buffer().as<PrecisionTrait<Precision::FP32>::value_type *>();

    int image_size = image.cols * image.rows;
    for (size_t pid = 0; pid < image_size; ++pid) {
        for (size_t ch = 0; ch < 1; ++ch) {
            input_data[ch * image_size + pid] = image.at<cv::Vec3b>(pid)[ch];
        }
    }
    // -----------------------------------------------------------------------------------------------------

    // --------------------------- 7. Do inference --------------------------------------------------------
    /* Running the request synchronously */
    std::cout << "Do inference... ";
    infer_request.Infer();
    // -----------------------------------------------------------------------------------------------------

    // --------------------------- 8. Process output ------------------------------------------------------
    Blob::Ptr output = infer_request.GetBlob(mOutputName);
    std::cout << "output.dims() = " << output->size() << std::endl;
    // TODO: output to float vector
    // -----------------------------------------------------------------------------------------------------

    std::cout << "Done!" << std::endl;

    std::vector<float> features;
    return features;
}
